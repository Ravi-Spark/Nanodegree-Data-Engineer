**Detail :**   
In this project, you'll apply what you've learned on data modeling with Postgres and build an ETL pipeline using Python. To complete the project, you will need to define fact and dimension tables for a star schema for a particular analytic focus, and write an ETL pipeline that transfers data from files in two local directories into these tables in Postgres using Python and SQL.

There are programming files sql_queries.py, create_tables.py, etl.py, etl.ipynb, test.ipynb.


Follow the process to run the project:

1. Open Terminal
2. Run Command"create_table.py" to create tables and database.
3. Run Command"elt.py" to process song data files
4. To test data insertion "test.ipynp" 

**Remember:**
Each time you run the cells above, remember to restart the notebook to close the connection to your database. Otherwise, you won't be able to run because of You can't make multiple connections with the same database.
